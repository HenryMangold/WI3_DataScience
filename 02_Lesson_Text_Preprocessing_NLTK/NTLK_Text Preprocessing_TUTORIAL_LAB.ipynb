{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Henryy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Henryy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Henryy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Henryy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#nltk.download('punkt')\n",
    "\n",
    "text=\"What brought Italy coach Antonio Conte to Chelsea as Jose Mourinho replacement?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'What brought Italy coach Antonio Conte to Chelsea as Jose Mourinho replacement'"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove punctuation from text\n",
    "import string\n",
    "\n",
    "def keep_only_words(text):\n",
    "    only_words=text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return only_words\n",
    "\n",
    "only_words=keep_only_words(text)\n",
    "only_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: []\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create empty data frame for the preprocessing pipeline to be build\n",
    "df_prep=pd.DataFrame()\n",
    "df_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "          Token\n0          What\n1       brought\n2         Italy\n3         coach\n4       Antonio\n5         Conte\n6            to\n7       Chelsea\n8            as\n9          Jose\n10     Mourinho\n11  replacement",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Token</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>brought</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Italy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>coach</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Antonio</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Conte</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>to</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Chelsea</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>as</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Jose</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Mourinho</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>replacement</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Word tokenization\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#Create function tokenize_to_list which returns a list of word tokens (passing a string as argument)\n",
    "def tokenize_to_list(text):\n",
    "    word_tokens=word_tokenize(text)\n",
    "    return word_tokens\n",
    "\n",
    "#Add new column to your data frame\n",
    "df_prep['Token']=tokenize_to_list(only_words)\n",
    "df_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "          Token Token and POS-Tag\n0          What           What-WP\n1       brought       brought-VBD\n2         Italy         Italy-NNP\n3         coach          coach-NN\n4       Antonio       Antonio-NNP\n5         Conte         Conte-NNP\n6            to             to-TO\n7       Chelsea       Chelsea-NNP\n8            as             as-IN\n9          Jose          Jose-NNP\n10     Mourinho      Mourinho-NNP\n11  replacement    replacement-NN",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Token</th>\n      <th>Token and POS-Tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What</td>\n      <td>What-WP</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>brought</td>\n      <td>brought-VBD</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Italy</td>\n      <td>Italy-NNP</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>coach</td>\n      <td>coach-NN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Antonio</td>\n      <td>Antonio-NNP</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Conte</td>\n      <td>Conte-NNP</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>to</td>\n      <td>to-TO</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Chelsea</td>\n      <td>Chelsea-NNP</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>as</td>\n      <td>as-IN</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Jose</td>\n      <td>Jose-NNP</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Mourinho</td>\n      <td>Mourinho-NNP</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>replacement</td>\n      <td>replacement-NN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#POS tagging\n",
    "#Create function token_and_tag_to_list and return result as a list\n",
    "def token_and_tag_to_list(normed_word_tokens):\n",
    "    #use nltk.pos_tag to create a list called \"upper_tokens_pos\"\n",
    "    upper_tokens_pos = nltk.pos_tag(normed_word_tokens)\n",
    "    \n",
    "    #concatenate upper tokens and the assigned POS tag to a new list \"token_and_tag\" (return value)\n",
    "    token_and_tag=[x[0]+'-'+x[1] for x in upper_tokens_pos]\n",
    "\n",
    "    return token_and_tag\n",
    "\n",
    "#Add new column to your data frame\n",
    "df_prep['Token and POS-Tag']=token_and_tag_to_list(df_prep['Token'])\n",
    "df_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmatization\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# function to dervive lemmas from token list\n",
    "def lemmatize_to_list():\n",
    "\n",
    "\n",
    "#Add new column to your data frame\n",
    "df_prep['Lemma']=lemmatize_to_list(df_prep['Token'])\n",
    "df_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stopword Removal\n",
    "#Import stopword dictionary\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#Create function non_stopword_token_to_list to return a list of non-stopword tokens\n",
    "#<<<< insert line of code here >>>>>\n",
    "    #Create a set holding english stopwords using the stopwords class\n",
    "    #<<<< insert line of code here >>>>>\n",
    "    \n",
    "    #create empty list for non_stopword_tokens\n",
    "    #<<<< insert line of code here >>>>>\n",
    "\n",
    "    #iterate tokens in series, if stop word, append non_stopword_tokens with '-', else keep token\n",
    "    #<<<< insert lines of code here >>>>>\n",
    "\n",
    "#Add new column to your data frame\n",
    "df_prep['Non-Stopword Token']=non_stopword_token_to_list(df_prep['Lemma'])\n",
    "df_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "#Create function stemmed_token_to_list to return stemmed list of tokens\n",
    "#<<<< insert line of code here >>>>>\n",
    "    #Intialize porter stemmer object\n",
    "    #<<<< insert line of code here >>>>>\n",
    "    #Initialize empty list for stemmed_tokens\n",
    "    stemmed_tokens=[]\n",
    "    #Iterate tokens in 'Upper Token'\n",
    "    #<<<< insert lines of code here >>>>>\n",
    "\n",
    "#Add new column to your data frame\n",
    "df_prep['Stemmed Token']=stemmed_token_to_list(df_prep['Non-Stopword Token'])\n",
    "df_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization to UPPERCASE\n",
    "#Create function upper_tokens_to_list which normalizes tokens to uppercase and returns result as a list\n",
    "#<<<< insert lines of code here >>>>>\n",
    "\n",
    "#Add new column to your data frame\n",
    "df_prep['Upper Token']=upper_tokens_to_list(df_prep['Stemmed Token'])\n",
    "df_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function called text_preprocessing_pipeline which calls all 7 functions in a row\n",
    "#passing a string and returning a data frame\n",
    "#<<<< insert lines of code here >>>>>\n",
    "    \n",
    "#Call your pipeline-function with a test document\n",
    "document1=\"Jack likes to watch movies. Sandra likes movies too.\"\n",
    "df_doc1=text_preprocessing_pipeline(document1)\n",
    "df_doc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "\n",
    "#Create a function to generate a list of ngrams from a sentance (passing sentance and n grams)\n",
    "#<<<< insert lines of code here >>>>>\n",
    "\n",
    "#concatenate df_doc1['Stemmed Token'] to a string (use blanks to seperate tokens) and delete '-' tokens\n",
    "#<<<< insert lines of code here >>>>>\n",
    "\n",
    "n_gram_list=create_n_grams_to_list(doc1_str,2)\n",
    "print(n_gram_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}