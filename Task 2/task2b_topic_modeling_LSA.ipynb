{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from scipy import spatial\n",
    "from pprint import pprint\n",
    "from datetime import date\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim.models import LsiModel\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.matutils import corpus2dense\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import task2a_prep_functions as p\n",
    "\n",
    "today = date.today()\n",
    "d1 = today.strftime('%d%m%Y')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# read in dataframe from csv\n",
    "data = pd.read_csv('results_scrapping.csv')\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# preprocess given text\n",
    "def preprocess(data):\n",
    "    # Remove punctuation\n",
    "    data['content_processed'] = data['Content'].map(lambda x: re.sub('[,\\.!?]', '', x))\n",
    "\n",
    "    # Convert text to lowercase\n",
    "    data['content_processed'] = data['content_processed'].map(lambda x: x.lower())\n",
    "\n",
    "    stop_words = stopwords.words('english')\n",
    "    stop_words.extend(['from', 'subject', 're', 'edu', 'use', 'de', 'km', 'one', 'two'])\n",
    "\n",
    "    def sent_to_words(sentences):\n",
    "        for sentence in sentences:\n",
    "            yield simple_preprocess(str(sentence), deacc=True) # -> True removes punctuations\n",
    "\n",
    "    def remove_stopwords(texts):\n",
    "        return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "    # Tokenizing and remove punctuation of processed content\n",
    "    data_list = data.content_processed.values.tolist()\n",
    "    data_words = list(sent_to_words(data_list))\n",
    "\n",
    "    # Lemmatization of processed content\n",
    "    data_lemmatize = p.lemmatize_to_list([data_words])[0]\n",
    "\n",
    "    # Remove stop words of processed content\n",
    "    data_words = remove_stopwords(data_lemmatize)\n",
    "    data['content_prep'] = data_words\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "data = preprocess(data)\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Latent Semantic Analysis (LSA)\n",
    "For LSA the following basic steps are required. These steps are combined in the Gensim LsiModel (yes for some reason they named it LSI) that will be used here.\n",
    "\n",
    "## 1.  TF-IDF Vectorization\n",
    "Goal is to create a document-term matrix that contains the tf-idf values for words within each document. A high tf-idf score represents a word that appears often in a document but not very often in the corpus. This means that this word is likely usefully for dokument classification. Words that appear often in a document but also often in the corpus will get a low tf-idf score.\n",
    "\n",
    "## 2. Singular Value Decomposition (SVD) for dimensionality reduction\n",
    "the resulting document-term matrix is a huge matrix with a lot of noisy and redundant information. Therefore, we want to reduce the dimensions to only a few latent topics that capture the relationships among the words and documents."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create dictionary and corpus\n",
    "corpus = data['content_prep']\n",
    "dictionary = corpora.Dictionary(corpus)\n",
    "print(dictionary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# convert corpus to bag of words\n",
    "bow = [dictionary.doc2bow(text) for text in corpus]\n",
    "len(bow)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# find the coherence score with a different number of topics\n",
    "for i in range(2,11):\n",
    "    lsi = LsiModel(bow, num_topics=i, id2word=dictionary)\n",
    "    coherence_model = CoherenceModel(model=lsi, texts=data['content_prep'], dictionary=dictionary, coherence='c_v')\n",
    "    coherence_score = coherence_model.get_coherence()\n",
    "    print('Coherence score with {} clusters: {}'.format(i, coherence_score))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# build LSA model\n",
    "lsa_model = LsiModel(bow, num_topics=10, id2word=dictionary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dt_matrix = corpus2dense(lsa_model[bow], len(lsa_model.projection.s)).T / lsa_model.projection.s\n",
    "dt_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inspect Topics\n",
    "The matrix plots a score for each document for each topic.\n",
    "Todo\n",
    "- Find corresponding topics for each number\n",
    "  - might be difficult since we don't even know if there is a word for each topic\n",
    "  - maybe find words that define each topic from tf-idf matrix\n",
    "- figure out how many topics we want"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pprint(lsa_model.print_topics())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Predicting closest document to input based on document topic matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get place of the closest document for each word\n",
    "# transform svd matrix to spacial KDtree\n",
    "tree = spatial.KDTree(dt_matrix)\n",
    "\n",
    "# transform a list of words with the fitted model to get their vector-representation\n",
    "input = [['sun', 'beach'], ['city', 'town'], ['mountain', 'hiking']]\n",
    "# Todo: Run Preprocessing over input\n",
    "\n",
    "\n",
    "# transform words with dict to bow\n",
    "input_bow = [dictionary.doc2bow(words) for words in input]\n",
    "\n",
    "input_topics = lsa_model.__getitem__(input_bow)\n",
    "# reformat to keep just values in tuples\n",
    "input_vecs = []\n",
    "for line in input_topics:\n",
    "    input_vecs.append([y[1] for y in line])\n",
    "\n",
    "# get closest document vector for each word vector\n",
    "for i, input_vec in enumerate(input_vecs):\n",
    "    query = tree.query(input_vec)\n",
    "    print(f'\"{input[i]}\" > \"{data.Place[query[1]]}\" Distance: {query[0]}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Script to train multiple LSA Models with different configurations and show differences in an Excel File"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# find the coherence score with a different number of topics\n",
    "for i in range(5, 35, 5):\n",
    "\n",
    "    model_name = f'lsa_{d1}_' + f'{i}' + 'topics'\n",
    "    dest_path = f'../results/{model_name}/'\n",
    "    if not os.path.exists(dest_path):\n",
    "        os.mkdir(f'../results/{model_name}/')\n",
    "\n",
    "    lsi = LsiModel(bow, num_topics=i, id2word=dictionary)\n",
    "    coherence_model = CoherenceModel(model=lsi, texts=data['content_prep'], dictionary=dictionary, coherence='c_v')\n",
    "    coherence_score = coherence_model.get_coherence()\n",
    "    # save Coherence Score to lsa model results directory\n",
    "    with open(f'../results/{model_name}/lsa_vis_prepared_' + str(i) + '_scores.txt', 'w') as f:\n",
    "        f.write(f'Coherence Score: {coherence_score}\\n')\n",
    "        f.close()\n",
    "\n",
    "    lsa_model = LsiModel(bow, num_topics=i, id2word=dictionary)\n",
    "\n",
    "    dt_matrix = corpus2dense(lsa_model[bow], len(lsa_model.projection.s)).T / lsa_model.projection.s\n",
    "    df_matrix = pd.DataFrame(dt_matrix)\n",
    "    df_matrix.to_csv(f'../results/{model_name}/lsa_vis_prepared_' + str(i) + '_matrix.csv', index=False, header=False)\n",
    "\n",
    "    # save dictionary to model results\n",
    "    dictionary.save(f'../results/{model_name}/lda_vis_prepared_' + str(i) + '_dictionary')\n",
    "\n",
    "    pprint(lsa_model.print_topics())\n",
    "\n",
    "    # get place of the closest document for each word\n",
    "    # transform svd matrix to spacial KDtree\n",
    "    tree = spatial.KDTree(dt_matrix)\n",
    "\n",
    "    # transform a list of words with the fitted model to get their vector-representation\n",
    "    input = [['sun', 'beach'], ['city', 'town'], ['mountain', 'hiking']]\n",
    "    # Todo: Run Preprocessing over input\n",
    "\n",
    "    # transform words with dict to bow\n",
    "    input_bow = [dictionary.doc2bow(words) for words in input]\n",
    "\n",
    "    input_topics = lsa_model.__getitem__(input_bow)\n",
    "    # reformat to keep just values in tuples\n",
    "    input_vecs = []\n",
    "    for line in input_topics:\n",
    "        input_vecs.append([y[1] for y in line])\n",
    "\n",
    "    # get closest document vector for each word vector\n",
    "    with open(f'../results/{model_name}/lsa_vis_prepared_' + str(i) + '_prediction.txt', 'w') as f:\n",
    "        for i, input_vec in enumerate(input_vecs):\n",
    "            query = tree.query(input_vec)\n",
    "            f.write(f'{input[i]} > \"{data.Place[query[1]]}\" - Distance: {query[0]}\\n')\n",
    "        f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### after running above cell you need to run \"task2b_topicmodel_lda_lsa_excel-result.ipynb\" with algorithm = lsa to merge model results into Excel File"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "wi3_datascience",
   "language": "python",
   "display_name": "WI3_DataScience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}